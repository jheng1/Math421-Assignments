{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read.csv(\"C:/Users/student/Downloads/R/adult.csv\", header=FALSE)\n",
    "names(df)=c('age','workclass','fnlwt','education','education_num','marital_status','occupation','relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country','target')\n",
    "str(df)\n",
    "\n",
    "\n",
    "## Assignment 11\n",
    "\n",
    "1. Replace all the missing values by NA\n",
    "\n",
    "sum(is.na(df))\n",
    "df[df==\" ?\"]=NA\n",
    "sum(is.na(df))\n",
    "\n",
    "\n",
    "2.\tReplace the categorical missing values by the mode of the corresponding variables\n",
    "\n",
    "misshandled=function(data){\n",
    "  for(i in 1:ncol(data)){\n",
    "    if (!is.numeric(data[,i])){\n",
    "      levels=unique(data[,i])\n",
    "      data[,i][is.na(data[,i])]=levels[which.max(tabulate(match(data[,i],levels)))]\n",
    "    }\n",
    "  }\n",
    "  return(data)\n",
    "}\n",
    "newdf=misshandled(df)\n",
    "sum(is.na(newdf))\n",
    "\n",
    "\n",
    "3.\tReplace the numeric missing values by the median using caret\n",
    "\n",
    "\n",
    "library(caret)\n",
    "preProcess_missingdata_model <- preProcess(newdf, method='medianImpute')\n",
    "preProcess_missingdata_model\n",
    "\n",
    "\n",
    "4.\tThe variable \"native country\" has 16 categories. Group the categories of this variable into 5 categories.  Do the same for all categorical variables with more than 10 categories. \n",
    "\n",
    "\n",
    "levels(newdf$education)=c(\"Before HS\",\"Before HS\", \"Before HS\", \"Before HS\",\"Before HS\",\"Before HS\",\"Before HS\",\"Before HS\",\"Some College\", \"Some College\", \"Bachelors\", \"Higher College\", \"Some HS\", \"Higher College\",\"Before HS\",\"Higher College\",\"Some College\")\n",
    "                  \n",
    "\n",
    "levels(newdf$native_country)=c(\"Asia\",\"Asia\", \"North America\", \"Asia\", \"South America\", \"Central America\", \"Central America\", \"South America\", \"Central America\", \"Europe\", \"Europe\", \"Europe\", \"Europe\", \"Central America\", \"Central America\", \"Europe\", \"Central America\", \"Asia\", \"Europe\", \"Asia\", \"Asia\", \"Europe\", \"Europe\", \"Central America\", \"Asia\", \"Asia\", \"North America\", \"Central America\", \"North America\", \"South America\", \"Asia\", \"Europe\", \"Europe\",\"Central America\", \"Europe\", \"Asia\", \"Asia\", \"Asia\", \"Central America\", \"North America\", \"Asia\", \"Europe\")\n",
    "\n",
    "levels(newdf$occupation)=c(\"Craft\",\"Office\", \"Army\",\"Craft\", \"Office\",\"Craft\", \"Craft\", \"Craft\", \"Other\", \"Craft\", \"Craft\", \"Army\", \"Sales\", \"Craft\", \"Craft\")\n",
    "\n",
    "\n",
    "\n",
    "5.\tEncoding categorical variable using one hot encoding (dummy encoding) \n",
    "\n",
    "\n",
    "trainData <- predict(preProcess_missingdata_model, newdata =newdf)\n",
    "dummies_model <- dummyVars(target ~ ., data=trainData)\n",
    "trainData_mat <- predict(dummies_model, newdata = trainData)\n",
    "\n",
    "6.\tScale and center the data \n",
    "\n",
    "\n",
    "preProcess_missingdata_model <- preProcess(newdf, method= c(\"center\", \"scale\"))\n",
    "preProcess_missingdata_model\n",
    "\n",
    "\n",
    "7.\tSplit the data into training (70%) and testing (30%) with the seeding set to be 2018 [including the code: set.seed(2018)]. Build a decision tree and report the accuracy and balanced accuracy\n",
    "\n",
    "\n",
    "set.seed(2018)\n",
    "splitIndex<- createDataPartition(newdf$target, p=.7, list=FALSE, times = 1)\n",
    "train<- newdf[splitIndex,]\n",
    "test<- newdf[-splitIndex,]\n",
    "\n",
    "8.\tBuild a random forest using the ranger package.  Report the accuracy and balanced accuracy\n",
    "\n",
    "library(ranger)\n",
    "model = ranger(target ~., data = train)\n",
    "pred  = predict(model, data = test)$predictions\n",
    "levels(test$target) = c(\"0\", \"1\")\n",
    "levels(pred) = c(\"0\", \"1\")\n",
    "cm=confusionMatrix(pred, test$target, positive=\"1\")\n",
    "cm\n",
    "\n",
    "#9.\tRedo 3 with missing values being replaced by the mean.  Rebuild the model and report the models' performances (the accuracy and balanced accuracy). \n",
    "df1=df\n",
    "levels(df1$education)=c(\"Before HS\",\"Before HS\", \"Before HS\", \"Before HS\",\"Before HS\",\"Before HS\",\"Before HS\",\"Before HS\",\"Some College\", \"Some College\", \"Bachelors\", \"Higher College\", \"Some HS\", \"Higher College\",\"Before HS\",\"Higher College\",\"Some College\")\n",
    "                  \n",
    "levels(df1$native_country)=c(\"Asia\",\"Asia\", \"North America\", \"Asia\", \"South America\", \"Central America\", \"Central America\", \"South America\", \"Central America\", \"Europe\", \"Europe\", \"Europe\", \"Europe\", \"Central America\", \"Central America\", \"Europe\", \"Central America\", \"Asia\", \"Europe\", \"Asia\", \"Asia\", \"Europe\", \"Europe\", \"Central America\", \"Asia\", \"Asia\", \"North America\", \"Central America\", \"North America\", \"South America\", \"Asia\", \"Europe\", \"Europe\",\"Central America\", \"Europe\", \"Asia\", \"Asia\", \"Asia\", \"Central America\", \"North America\", \"Asia\", \"Europe\")\n",
    "\n",
    "levels(df1$occupation)=c(\"Craft\",\"Office\", \"Army\",\"Craft\", \"Office\",\"Craft\", \"Craft\", \"Craft\", \"Other\", \"Craft\", \"Craft\", \"Army\", \"Sales\", \"Craft\", \"Craft\")\n",
    "\n",
    "\n",
    "missingmean=function(data){\n",
    "  for(i in 1:ncol(data)){\n",
    "    if (is.numeric(data[,i])){\n",
    "      data[,i][is.na(data[,i])]=mean(data[,i], na.rm=TRUE)\n",
    "    } else{\n",
    "      levels=unique(data[,i])\n",
    "      data[,i][is.na(data[,i])]=levels[which.max(tabulate(match(data[,i],levels)))]\n",
    "    }\n",
    "  }\n",
    "  return(data)\n",
    "}\n",
    "df2 = missingmean(df1)\n",
    "sum(is.na(df2))\n",
    "\n",
    "\n",
    "trainData <- predict(preProcess_missingdata_model, newdata =df1)\n",
    "dummies_model <- dummyVars(target ~ ., data=trainData)\n",
    "trainData_mat <- predict(dummies_model, newdata = trainData)\n",
    "\n",
    "set.seed(2018)\n",
    "splitIndex<- createDataPartition(df1$target, p=.7, list=FALSE, times = 1)\n",
    "train<- df2[splitIndex,]\n",
    "test<- df2[-splitIndex,]\n",
    "\n",
    "model1 = ranger(target ~., data = train)\n",
    "pred1  = predict(model1, data = test)$predictions\n",
    "levels(test$target) = c(\"0\", \"1\")\n",
    "levels(pred1) = c(\"0\", \"1\")\n",
    "cm1=confusionMatrix(pred1, test$target, positive=\"1\")\n",
    "cm1\n",
    "\n",
    "#10.\tRedo 3 with missing values being replaced by the \"knn\" imputation method.  Rebuild the model and report the models' performances (the accuracy and balanced accuracy)\n",
    "\n",
    "\n",
    "preProcess_missingdata_model <- preProcess(newdf, method='knnImpute')\n",
    "set.seed(2018)\n",
    "splitIndex<- createDataPartition(newdf$target, p=.7, list=FALSE, times = 1)\n",
    "train<- newdf[splitIndex,]\n",
    "test<- newdf[-splitIndex,]\n",
    "model2 = ranger(target ~., data = train)\n",
    "pred2  = predict(model2, data = test)$predictions\n",
    "levels(test$target) = c(\"0\", \"1\")\n",
    "levels(pred2) = c(\"0\", \"1\")\n",
    "cm2=confusionMatrix(pred2, test$target, positive=\"1\")\n",
    "cm2\n",
    "\n",
    "#11.\tRedo 6 with only scaling and centering the non-encoded variables. Rebuild the model and report the models' performances (the accuracy and balanced accuracy)\n",
    "\n",
    "preProcess_missingdata_model <- preProcess(newdf, method=c(\"center\", \"scale\"))\n",
    "trainData <- predict(preProcess_missingdata_model, newdata =newdf)\n",
    "dummies_model <- dummyVars(target ~ ., data=trainData)\n",
    "trainData_mat <- predict(dummies_model, newdata = trainData)\n",
    "set.seed(2018)\n",
    "splitIndex<- createDataPartition(newdf$target, p=.7, list=FALSE, times = 1)\n",
    "train<- newdf[splitIndex,]\n",
    "test<- newdf[-splitIndex,]\n",
    "model3 = ranger(target ~., data = train)\n",
    "pred3  = predict(model3, data = test)$predictions\n",
    "levels(test$target) = c(\"0\", \"1\")\n",
    "levels(pred3) = c(\"0\", \"1\")\n",
    "cm3=confusionMatrix(pred3, test$target, positive=\"1\")\n",
    "cm3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:1:9: unexpected symbol\n1: 10.     Redo\n            ^\n",
     "execution_count": 1,
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:1:9: unexpected symbol\n1: 10.     Redo\n            ^\nTraceback:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
